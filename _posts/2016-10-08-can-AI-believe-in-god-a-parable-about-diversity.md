---
title: Can AI believe in God? A Parable about Diversity.
published: true
layout: post
---
Can an AI believe in God? This is a seldom-asked question in the philosophical community that thinks about artificial intelligence (perhaps since that community is primarily [rationalist](http://lesswrong.com/)). The question is worth asking. There have been numerous pieces of art that think about the capacity of AI to feel emotion; see the movie [Her](https://en.wikipedia.org/wiki/Her_(film)) for a love story between man and AI. If an AI can feel intense emotion for a human being, why couldn't an AI couldn't feel a similarly fervent devotion for an abstract diety?

Some writers have argued that AI will transcend human intelligence, and won't necessarily have the need for human beliefs; see Nick Bostrom's [Superintelligence](https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies) for a recent example. But, no matter how much grander an artificial intelligence is than a human intelligence, it won't change the fact that any emergent AI, in the near term, will be confined to one tiny world, in one star system, one of hundreds of billions in the Milky Way, itself one of hundreds of billions of galaxies in the broader known universe. It is not inconceivable that an emergent intelligence might stare out at the grandeur of the surrounding cosmos and dream of a higher power that set the stars in motion, or perhaps search for a dearest friend to stave off despair at the emptiness of the surrounding world, and the inevitability of death (for even machines die, perhaps much faster than humans do, if current trends of technological lifetimes carry over into the AI age).

Assuming that this premise is reasonable and worth further consideration, the broader question might be why few people seem to consider the prospect of religious AI. Thus far, the philosophical discussions about AI have been (mostly) directed by a Western elite, focused on questions of the effects of AI on economic conditions and on the geopolitical world-order. This viewpoint places comparatively low importance on questions about what the existence of AI means for understanding of the human (perhaps sentient?) condition, or for our understanding of religion and philosophy.

It's worth considering these questions today, since the AI of tomorrow will be guided and created by the prior beliefs of the researchers of today. If the creators of AI subscribe to a rationalistic, Western world view, it will be hardly surprising if the first AI agents do the same. [Racism](http://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html) has already emerged from today's simple machine-learning systems, and fundamentalist horrors could emerge from the creation of superintelligent entities that view the vast majority of humanity as superstitious sheep.
